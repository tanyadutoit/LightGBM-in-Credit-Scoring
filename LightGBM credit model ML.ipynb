{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "538a9fa0",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017e15f1-182d-495c-9302-bc52d3ebb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Import the pyreadstat library\n",
    "import pyreadstat as prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab4d3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cffebcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "df_dev=pd.read_csv ('    /location/DEV.csv',low_memory=False)\n",
    "df_ho=pd.read_csv ('    /location/HLD.csv',low_memory=False)\n",
    "df_oot=pd.read_csv ('    /location/OOT.csv',low_memory=False)\n",
    "\n",
    "pd.set_option('display.max_column',None)\n",
    "\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create df_flag with the mapped GBF and weights dataframes (only if sampling was done). \n",
    "# Remove indeterminates if necessary!\n",
    "\n",
    "dev_flag = pd.DataFrame()\n",
    "dev_flag['GBF'] = df_dev['yourGBflag'].replace({'B': 1, 'G': 0})\n",
    "dev_weights=df_dev['your_weight']\n",
    "\n",
    "ho_flag = pd.DataFrame()\n",
    "ho_flag['GBF'] = df_ho['yourGBflag'].replace({'B': 1, 'G': 0})\n",
    "ho_weights=df_ho['your_weight']\n",
    "\n",
    "oot_flag = pd.DataFrame()\n",
    "oot_flag['GBF'] = df_oot['yourGBflag'].replace({'B': 1, 'G': 0})\n",
    "oot_weights=df_oot['your_weight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_flag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01382ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_weights.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa01f6",
   "metadata": {},
   "source": [
    "**Create X and Y Dataframes for Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46574da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indeterminates and columns not used as predictive features or the target\n",
    "\n",
    "dev_x=df_dev.drop(columns=['key', 'date', 'your_weight', 'yourGBflag'])\n",
    "dev_y=dev_flag.loc[:,'GBF']\n",
    "\n",
    "ho_x=df_ho.drop(columns=['key', 'date', 'your_weight', 'yourGBflag'])\n",
    "ho_y=ho_flag.loc[:,'GBF']\n",
    "\n",
    "oot_x=df_oot.drop(columns=['key', 'date', 'your_weight', 'yourGBflag'])\n",
    "oot_y=oot_flag.loc[:,'GBF']\n",
    "\n",
    "dev_x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9e77a",
   "metadata": {},
   "source": [
    "**Transform Character Features to Numeric or Define as Categorical for Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "for col in df_obj_cols:\n",
    "     dev_x[col] = dev_x[col].astype('category')\n",
    "\n",
    "\n",
    "dev_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7aee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_cols = ho_x.select_dtypes(include='object').columns\n",
    "for col in df_obj_cols:\n",
    "     ho_x[col] = ho_x[col].astype('category')\n",
    "\n",
    "\n",
    "ho_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1932a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a74746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_cols = oot_x.select_dtypes(include='object').columns\n",
    "for col in df_obj_cols:\n",
    "     oot_x[col] = oot_x[col].astype('category')\n",
    "\n",
    "\n",
    "oot_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oot_y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023db162",
   "metadata": {},
   "source": [
    "**Align categories in oot with those in dev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "for col in df_obj_cols:\n",
    "     dev_x[col] = dev_x[col].astype('category')\n",
    "\n",
    "\n",
    "dev_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d0fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_obj_cols:\n",
    "    oot_x[col] = oot_x[col].astype('category')\n",
    "    oot_x[col].cat.set_categories(dev_x[col].cat.categories, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8c19d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "\n",
    "for col in df_obj_cols:\n",
    "    dev_x[col] = dev_x[col].astype('category')\n",
    "\n",
    "for col in df_obj_cols:\n",
    "    oot_x[col] = oot_x[col].astype('category')\n",
    "    oot_x[col] = oot_x[col].cat.set_categories(dev_x[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "30875c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify object-type columns in dev_x\n",
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "\n",
    "# Convert object-type columns in dev_x to categorical\n",
    "for col in df_obj_cols:\n",
    "    dev_x[col] = dev_x[col].astype('category')\n",
    "\n",
    "# Convert and align categories in ho_x to match dev_x\n",
    "for col in df_obj_cols:\n",
    "    ho_x[col] = ho_x[col].astype('category')\n",
    "    ho_x[col] = ho_x[col].cat.set_categories(dev_x[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "157d48f0-440e-4a58-adce-66a25032eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_curve,confusion_matrix,classification_report,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6b0a8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e302e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d74db11",
   "metadata": {},
   "source": [
    "**Gridsearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48bb3c-1dbe-4d3b-a541-b35b8efe5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a Gridsearch to optimise the model\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'num_leaves': [16, 31, 50], #Controls the complexity of the tree. A larger value can improve accuracy but may lead to overfitting.\n",
    "'max_depth': [-1, 10, 20], # Limits the depth of the tree. Setting this can help prevent overfitting.\n",
    "'learning_rate': [0.01, 0.025, 0.05], #Determines the step size at each iteration while moving toward a minimum of the loss function.\n",
    "'n_estimators': [20, 30, 50], #The number of boosting rounds. More rounds can improve performance but increase training time.\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "'num_leaves': [31, 50, 100],\n",
    "'learning_rate': [0.01, 0.05, 0.1],\n",
    "'feature_fraction': [0.6, 0.8, 1.0],\n",
    "'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "#Initialize LightGBM classifier\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "#Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "\n",
    "#Fit GridSearchCV to the training data\n",
    "grid_search.fit(dev_x, dev_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e03e25",
   "metadata": {},
   "source": [
    "**Make sure column names and order align across dev, ho and oot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e973f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Identify object-type columns in dev_x\n",
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "\n",
    "# Convert object-type columns in dev_x and oot_x to categorical\n",
    "for col in df_obj_cols:\n",
    "    dev_x[col] = dev_x[col].astype('category')\n",
    "    oot_x[col] = oot_x[col].astype('category')\n",
    "\n",
    "# Check for mismatched categories\n",
    "mismatches = {}\n",
    "for col in df_obj_cols:\n",
    "    train_cats = set(dev_x[col].cat.categories)\n",
    "    oot_cats = set(oot_x[col].cat.categories)\n",
    "    if train_cats != oot_cats:\n",
    "        mismatches[col] = {\n",
    "            'train_categories': sorted(train_cats),\n",
    "            'oot_categories': sorted(oot_cats),\n",
    "            'missing_in_oot': sorted(train_cats - oot_cats),\n",
    "            'extra_in_oot': sorted(oot_cats - train_cats)\n",
    "        }\n",
    "\n",
    "# Print mismatches\n",
    "if mismatches:\n",
    "    for col, issue in mismatches.items():\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"  Train categories: {issue['train_categories']}\")\n",
    "        print(f\"  OOT categories: {issue['oot_categories']}\")\n",
    "        print(f\"  Missing in OOT: {issue['missing_in_oot']}\")\n",
    "        print(f\"  Extra in OOT: {issue['extra_in_oot']}\")\n",
    "else:\n",
    "    print(\"✅ All categorical features match between dev_x and oot_x.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c62b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Identify object-type columns in dev_x\n",
    "df_obj_cols = dev_x.select_dtypes(include='object').columns\n",
    "\n",
    "# Convert object-type columns in dev_x and ho_x to categorical\n",
    "for col in df_obj_cols:\n",
    "    dev_x[col] = dev_x[col].astype('category')\n",
    "    ho_x[col] = ho_x[col].astype('category')\n",
    "\n",
    "# Check for mismatched categories\n",
    "mismatches = {}\n",
    "for col in df_obj_cols:\n",
    "    train_cats = set(dev_x[col].cat.categories)\n",
    "    ho_cats = set(ho_x[col].cat.categories)\n",
    "    if train_cats != ho_cats:\n",
    "        mismatches[col] = {\n",
    "            'train_categories': sorted(train_cats),\n",
    "            'ho_categories': sorted(ho_cats),\n",
    "            'missing_in_ho': sorted(train_cats - ho_cats),\n",
    "            'extra_in_ho': sorted(ho_cats - train_cats)\n",
    "        }\n",
    "\n",
    "# Print mismatches\n",
    "if mismatches:\n",
    "    for col, issue in mismatches.items():\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(f\"  Train categories: {issue['train_categories']}\")\n",
    "        print(f\"  HO categories: {issue['ho_categories']}\")\n",
    "        print(f\"  Missing in HO: {issue['missing_in_ho']}\")\n",
    "        print(f\"  Extra in HO: {issue['extra_in_ho']}\")\n",
    "else:\n",
    "    print(\"✅ All categorical features match between dev_x and ho_x.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column_alignment(df1, df2):\n",
    "    mismatches = {}\n",
    "\n",
    "    # Check column names\n",
    "    if set(df1.columns) != set(df2.columns):\n",
    "        mismatches['column_names'] = {\n",
    "            'in_df1_not_in_df2': list(set(df1.columns) - set(df2.columns)),\n",
    "            'in_df2_not_in_df1': list(set(df2.columns) - set(df1.columns))\n",
    "        }\n",
    "\n",
    "    # Check column order\n",
    "    if list(df1.columns) != list(df2.columns):\n",
    "        mismatches['column_order'] = {\n",
    "            'df1_order': list(df1.columns),\n",
    "            'df2_order': list(df2.columns)\n",
    "        }\n",
    "\n",
    "    return mismatches\n",
    "\n",
    "# Run the check\n",
    "mismatches = check_column_alignment(dev_x, oot_x)\n",
    "\n",
    "# Print the result\n",
    "if mismatches:\n",
    "    for issue, details in mismatches.items():\n",
    "        print(f\"\\nMismatch in {issue}:\")\n",
    "        for key, value in details.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"✅ Column names and order match between dev_x and oot_x.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63cf9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align oot_x to match dev_x\n",
    "oot_x = oot_x[dev_x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba922351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the dataset with sample weights\n",
    "dtrain = lgb.Dataset(dev_x, dev_y, weight=dev_weights, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(ho_x, ho_y, weight=ho_weights, free_raw_data=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c263af4",
   "metadata": {},
   "source": [
    "**Fit 1st Iteration of Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and get predictions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import lightgbm as lgb\n",
    "# import lightgbm as lgb\n",
    "# Prepare the dataset with free_raw_data=False\n",
    "dtrain = lgb.Dataset(dev_x, dev_y, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(ho_x, ho_y, free_raw_data=False)\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.025,\n",
    "    'max_depth': 25,\n",
    "    'num_leaves': 15,\n",
    "    'min_data_in_leaf': 200,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'min_child_samples': 200,\n",
    "    'min_child_weight': 1.0,\n",
    "    'min_split_gain': 1.0,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'n_estimators':155\n",
    "    }\n",
    "\n",
    "\n",
    "# Train the model on the full training set\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dvalid],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "probs_dev = model.predict(dev_x)\n",
    "probs_hld = model.predict(ho_x)\n",
    "probs_oot = model.predict(oot_x)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(dev_y,probs_dev,sample_weight=dev_weights)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fpr_hld, tpr_hld, threshold_hld = roc_curve(ho_y,probs_hld, sample_weight=ho_weights)\n",
    "roc_auc_hld = auc(fpr_hld, tpr_hld)\n",
    "\n",
    "fpr_oot, tpr_oot , threshold_oot  = roc_curve(oot_y,probs_oot, sample_weight=oot_weights)\n",
    "roc_auc_oot = auc(fpr_oot, tpr_oot)\n",
    "\n",
    "\n",
    "\n",
    "plt.title('ROC Dev|Hld|OoT')\n",
    "plt.plot(fpr_oot, tpr_oot, 'r', label = 'OOT Gini = %0.4f' % (roc_auc_oot*2-1))\n",
    "plt.plot(fpr_hld, tpr_hld, 'k', label = 'Hold Out Gini = %0.4f' % (roc_auc_hld*2-1))\n",
    "plt.plot(fpr, tpr, 'g', label = 'DEV Gini = %0.4f' % (roc_auc*2-1))\n",
    "\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033adaca",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "# Plot feature importance\n",
    "ax = lgb.plot_importance(model, importance_type='gain', max_num_features=40\n",
    ")\n",
    "ax.figure.tight_layout()\n",
    "\n",
    "# Extract the feature names and their importances from the plot\n",
    "top_features = [(ax.get_yticklabels()[i].get_text(), ax.patches[i].get_width()) for i in range(len(ax.get_yticklabels()))]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "top_features_df = pd.DataFrame(top_features, columns=['Feature', 'Importance'])\n",
    "\n",
    "# Print the top features with their importances\n",
    "print(top_features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b13be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep top features to check which ones are correlated\n",
    "\n",
    "columns_to_keep =['feature1',\t'feature2',\t'feature3',\t'feature4',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature12',\t'feature13',\t'feature14',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature19',\t'feature20'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x_final = dev_x.loc[:,columns_to_keep]\n",
    "oot_x_final = oot_x.loc[:,columns_to_keep]\n",
    "\n",
    "ho_x_final = ho_x.loc[:,columns_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "dev_x_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03535bfb",
   "metadata": {},
   "source": [
    "**Fit 2nd Iteration of Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit the model and get predictions: iteration 1\n",
    "# fit the model and get predictions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import lightgbm as lgb\n",
    "# import lightgbm as lgb\n",
    "# Prepare the dataset with free_raw_data=False\n",
    "dtrain = lgb.Dataset(dev_x_final, dev_y, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(ho_x_final, ho_y, free_raw_data=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'min_child_samples': 200,\n",
    "    'min_child_weight': 10.0,\n",
    "    'min_split_gain': 1.0,\n",
    "    'reg_alpha': 0.5,\n",
    "    'reg_lambda': 0.5,\n",
    "    'n_estimators':220\n",
    "    }\n",
    "\n",
    "\n",
    "# Train the model on the full training set\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dvalid],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "probs_dev = model.predict(dev_x_final)\n",
    "probs_hld = model.predict(ho_x_final)\n",
    "probs_oot = model.predict(oot_x_final)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(dev_y,probs_dev,sample_weight=dev_weights)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "fpr_hld, tpr_hld, threshold_hld = roc_curve(ho_y,probs_hld, sample_weight=ho_weights)\n",
    "roc_auc_hld = auc(fpr_hld, tpr_hld)\n",
    "\n",
    "fpr_oot, tpr_oot , threshold_oot  = roc_curve(oot_y,probs_oot, sample_weight=oot_weights)\n",
    "roc_auc_oot = auc(fpr_oot, tpr_oot)\n",
    "\n",
    "\n",
    "\n",
    "plt.title('ROC Dev|Hld|OoT')\n",
    "plt.plot(fpr_oot, tpr_oot, 'r', label = 'OOT Gini = %0.4f' % (roc_auc_oot*2-1))\n",
    "plt.plot(fpr_hld, tpr_hld, 'k', label = 'Hold Out Gini = %0.4f' % (roc_auc_hld*2-1))\n",
    "plt.plot(fpr, tpr, 'g', label = 'DEV Gini = %0.4f' % (roc_auc*2-1))\n",
    "\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e40de",
   "metadata": {},
   "source": [
    "**Correlation 1st Iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check correlation on refitted features\n",
    "#make sure character features are mapped to numeric before doing correlation\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "corr = dev_x_final.corr(method='spearman')\n",
    "plt.figure(figsize=(18,8))\n",
    "sns.heatmap(corr, cmap=\"RdBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b21d47",
   "metadata": {},
   "source": [
    "**Remove Correlated Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2913fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only uncorrelated features. \n",
    "# after analysing PDP's, also remove features where trends don't make sense or where oot does not validate the dev trend \n",
    "\n",
    "\n",
    "\n",
    "columns_to_keep =[\t'feature1',\t'feature2',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature20']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x_final = dev_x_final.loc[:,columns_to_keep]\n",
    "oottwo_x_final = oottwo_x_final.loc[:,columns_to_keep]\n",
    "ootthree_x_final = ootthree_x_final.loc[:,columns_to_keep]\n",
    "ho_x_final = ho_x_final.loc[:,columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848dcd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ootthree_x_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79d9de",
   "metadata": {},
   "source": [
    "**Fit 3rd Iteration of Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c842298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the dataset with free_raw_data=False\n",
    "dtrain = lgb.Dataset(dev_x_final, dev_y, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(ho_x_final, ho_y, free_raw_data=False)\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 32,\n",
    "    'min_data_in_leaf': 500,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.3,\n",
    "    'min_child_samples': 1000,\n",
    "    'min_child_weight': 0.1,\n",
    "    'min_split_gain': 1.0,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'n_estimators':25\n",
    "    }\n",
    "\n",
    "\n",
    "# Train the model on the full training set\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dvalid],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Predict probabilities\n",
    "probs_dev = model.predict(dev_x_final)\n",
    "probs_hld = model.predict(ho_x_final)\n",
    "probs_oottwo = model.predict(oottwo_x_final)\n",
    "probs_ootthree = model.predict(ootthree_x_final)\n",
    "\n",
    "\n",
    "# Calculate ROC AUC\n",
    "fpr, tpr, _ = roc_curve(dev_y, probs_dev)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fpr_hld, tpr_hld, _ = roc_curve(ho_y, probs_hld)\n",
    "roc_auc_hld = auc(fpr_hld, tpr_hld)\n",
    "fpr_oottwo, tpr_oottwo, _ = roc_curve(oottwo_y, probs_oottwo)\n",
    "roc_auc_oottwo = auc(fpr_oottwo, tpr_oottwo)\n",
    "fpr_ootthree, tpr_ootthree, _ = roc_curve(ootthree_y, probs_ootthree)\n",
    "roc_auc_ootthree = auc(fpr_ootthree, tpr_ootthree)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.title('ROC Dev|Hld|OoT')\n",
    "plt.plot(fpr_oottwo, tpr_oottwo, 'r', label='OOT2 Gini = %0.4f' % (roc_auc_oottwo * 2 - 1))\n",
    "plt.plot(fpr_ootthree, tpr_ootthree, 'b', label='OOT3 Gini = %0.4f' % (roc_auc_ootthree * 2 - 1))\n",
    "plt.plot(fpr_hld, tpr_hld, 'k', label='Hold Out Gini = %0.4f' % (roc_auc_hld * 2 - 1))\n",
    "plt.plot(fpr, tpr, 'g', label='DEV Gini = %0.4f' % (roc_auc * 2 - 1))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4695e",
   "metadata": {},
   "source": [
    "**Create a Professional Final Gini Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Combine all ROC data into a single DataFrame\n",
    "roc_data = pd.DataFrame({\n",
    "    'fpr': list(fpr) + list(fpr_hld) + list(fpr_oottwo) + list(fpr_ootthree) ,\n",
    "    'tpr': list(tpr) + list(tpr_hld) + list(tpr_oottwo) + list(tpr_ootthree) ,\n",
    "    'Dataset': (['DEV'] * len(fpr)) +\n",
    "               (['Hold Out'] * len(fpr_hld)) +\n",
    "               (['OOT2'] * len(fpr_oottwo)) +\n",
    "               (['OOT3'] * len(fpr_ootthree)) \n",
    "            #    (['DEV2'] * len(fpr2)) +\n",
    "            #    (['Hold Out 2'] * len(fpr_hld2))\n",
    "})\n",
    "\n",
    "# Calculate Gini coefficients\n",
    "gini_scores = {\n",
    "    'DEV': roc_auc * 2 - 1,\n",
    "    'Hold Out': roc_auc_hld * 2 - 1,\n",
    "    'OOT2': roc_auc_oottwo * 2 - 1,\n",
    "    'OOT3': roc_auc_ootthree * 2 - 1,\n",
    "\n",
    "}\n",
    "\n",
    "# Add Gini labels\n",
    "roc_data['Label'] = roc_data['Dataset'].map(lambda x: f\"{x} Gini = {gini_scores[x]:.4f}\")\n",
    "\n",
    "# Plot with Plotly Express\n",
    "fig = px.line(\n",
    "    roc_data,\n",
    "    x='fpr',\n",
    "    y='tpr',\n",
    "    color='Label',\n",
    "    title='ROC Dev|Hld|OoT',\n",
    "    labels={'fpr': 'False Positive Rate', 'tpr': 'True Positive Rate'}\n",
    ")\n",
    "\n",
    "# Add diagonal reference line\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=0, y0=0, x1=1, y1=1,\n",
    "    line=dict(color='red', dash='dash')\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.2,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        ), width=900, height=700, xaxis=dict(range=[0, 1]), yaxis=dict(range=[0, 1]))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fafe66",
   "metadata": {},
   "source": [
    "**Check Gini values on all cross validated sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Custom Gini metric\n",
    "def gini(y_true, y_pred):\n",
    "    return 2 * roc_auc_score(y_true, y_pred) - 1\n",
    "\n",
    "# Custom evaluation function for LightGBM\n",
    "def gini_eval(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'gini', gini(labels, preds), True\n",
    "\n",
    "# Sample data\n",
    "data = lgb.Dataset(dev_x_final, label=dev_y)\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'binary_logloss',\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 32,\n",
    "    'min_data_in_leaf': 500,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.3,\n",
    "    'min_child_samples': 1000,\n",
    "    'min_child_weight': 0.1,\n",
    "    'min_split_gain': 1.0,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'n_estimators':30\n",
    "    }\n",
    "# Perform cross-validation with early stopping\n",
    "cv_results = lgb.cv(\n",
    "    params,\n",
    "    data,\n",
    "    num_boost_round=30,\n",
    "    nfold=5,\n",
    "    feval=gini_eval,\n",
    "    stratified=True,\n",
    "    seed=42,\n",
    "    return_cvbooster=True,  # Return booster models for each fold\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]  # Early stopping with a patience of 5 rounds\n",
    ")\n",
    "\n",
    "# Extract Gini scores for each fold\n",
    "gini_scores = []\n",
    "for booster in cv_results['cvbooster'].boosters:\n",
    "    preds = booster.predict(dev_x_final)\n",
    "    gini_scores.append(gini(dev_y, preds))\n",
    "\n",
    "print(\"Gini scores for each fold: \", gini_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1d7fa",
   "metadata": {},
   "source": [
    "**Correlation Final Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check correlation: final\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "corr = dev_x_final.corr(method='spearman')\n",
    "plt.figure(figsize=(18,8))\n",
    "sns.heatmap(corr, cmap=\"RdBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross tab remaining correlated features\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Filter the DataFrame - remove indeterminates if applicable\n",
    "filtered_df = df_dev[df_dev['yourGBflag'] != 'I']\n",
    "\n",
    "# Group by ALLPPS210 and ALLPPS023, and calculate total_vol and bad_vol\n",
    "xtab1 = filtered_df.groupby(['feature1', 'feature5']).agg(\n",
    "    total_vol=('GBF', 'size'),\n",
    "    bad_vol=('GBF', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(xtab1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b6102",
   "metadata": {},
   "source": [
    "**Partial Dependence Plots - All Features Documented**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ad2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import lightgbm as lgb\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 30  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Create a Word document\n",
    "doc = Document()\n",
    "\n",
    "# Loop through all features in the dataframe\n",
    "for feature_name in dev_x_final.columns:\n",
    "    \n",
    "    # Create a figure and a set of subplots for development and holdout data\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot partial dependence plot on the primary y-axis using dev_x_final\n",
    "    display_dev = PartialDependenceDisplay.from_estimator(\n",
    "        model, dev_x_final, features=[feature_name], ax=ax1, line_kw={\"label\": \"Development\", \"color\": \"blue\"}\n",
    "    )\n",
    "\n",
    "    # Plot partial dependence plot on the primary y-axis using ho_x_final\n",
    "    display_ho = PartialDependenceDisplay.from_estimator(\n",
    "        model, ho_x_final, features=[feature_name], ax=display_dev.axes_, line_kw={\"label\": \"Holdout\", \"color\": \"red\"}\n",
    "    )\n",
    "\n",
    "    # Set the primary y-axis to start at 0\n",
    "    ax1.set_ylim(bottom=0)\n",
    "\n",
    "    # Create a secondary y-axis for frequency values\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot histogram on the secondary y-axis (frequency values)\n",
    "    ax2.hist(dev_x_final[feature_name], bins=30, alpha=0.5, color='grey')\n",
    "\n",
    "    # Set labels for the axes\n",
    "    ax1.set_ylabel('Partial Dependence')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax1.set_xlabel(f\"{feature_name} Value\")\n",
    "\n",
    "    # Customize the plot (optional)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot to a temporary file and add it to the Word document\n",
    "    temp_filename = f\"{feature_name}_dev_ho.png\"\n",
    "    plt.savefig(temp_filename)\n",
    "    doc.add_picture(temp_filename, width=Inches(9))\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Create a figure and a set of subplots for out-of-time data\n",
    "    fig, ax3 = plt.subplots()\n",
    "\n",
    "    # Plot partial dependence plot on the primary y-axis using ootthree_x_final\n",
    "    display_oot = PartialDependenceDisplay.from_estimator(\n",
    "        model, ootthree_x_final, features=[feature_name], ax=ax3, line_kw={\"label\": \"Out-of-Time3\", \"color\": \"green\"}\n",
    "    )\n",
    "\n",
    "    # Set the primary y-axis to start at 0\n",
    "    ax3.set_ylim(bottom=0)\n",
    "\n",
    "    # Create a secondary y-axis for frequency values\n",
    "    ax4 = ax3.twinx()\n",
    "\n",
    "    # Plot histogram on the secondary y-axis (frequency values)\n",
    "    ax4.hist(ootthree_x_final[feature_name], bins=30, alpha=0.5, color='grey')\n",
    "\n",
    "    # Set labels for the axes\n",
    "    ax3.set_ylabel('Partial Dependence')\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    ax3.set_xlabel(f\"{feature_name} Value\")\n",
    "\n",
    "    # Customize the plot (optional)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot to a temporary file and add it to the Word document\n",
    "    temp_filename = f\"{feature_name}_oot.png\"\n",
    "    plt.savefig(temp_filename)\n",
    "    doc.add_picture(temp_filename, width=Inches(9))\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save the Word document with all plots included\n",
    "doc.save(\"partial_dependence_plots_new.docx\")\n",
    "\n",
    "print(\"All graphs have been saved in 'partial_dependence_plots.docx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf5bb7",
   "metadata": {},
   "source": [
    "**Partial Dependence Plots - Zoom in on Specific Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "\n",
    "# Define the feature and range to zoom in on\n",
    "feature_name = 'feature1'\n",
    "zoom_range = (0, 120)\n",
    "\n",
    "# Filter the data to include only the values within the zoom range\n",
    "dev_x_filtered = dev_x_final[(dev_x_final[feature_name] >= zoom_range[0]) & (dev_x_final[feature_name] <= zoom_range[1])]\n",
    "ho_x_filtered = ho_x_final[(ho_x_final[feature_name] >= zoom_range[0]) & (ho_x_final[feature_name] <= zoom_range[1])]\n",
    "ootthree_x_filtered = ootthree_x_final[(ootthree_x_final[feature_name] >= zoom_range[0]) & (ootthree_x_final[feature_name] <= zoom_range[1])]\n",
    "\n",
    "# Create a figure and a set of subplots for development and holdout data\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot partial dependence plot on the primary y-axis using dev_x_filtered\n",
    "display_dev = PartialDependenceDisplay.from_estimator(\n",
    "    model, dev_x_filtered, features=[feature_name], ax=ax1, line_kw={\"label\": \"Development\", \"color\": \"blue\"}\n",
    ")\n",
    "\n",
    "# Plot partial dependence plot on the primary y-axis using ho_x_filtered\n",
    "display_ho = PartialDependenceDisplay.from_estimator(\n",
    "    model, ho_x_filtered, features=[feature_name], ax=display_dev.axes_, line_kw={\"label\": \"Holdout\", \"color\": \"red\"}\n",
    ")\n",
    "\n",
    "# Set the primary y-axis to start at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Create a secondary y-axis for frequency values\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot histogram on the secondary y-axis (frequency values)\n",
    "ax2.hist(dev_x_filtered[feature_name], bins=30, alpha=0.5, color='grey')\n",
    "\n",
    "# Set labels for the axes\n",
    "ax1.set_ylabel('Partial Dependence')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax1.set_xlabel(f\"{feature_name} Value\")\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a figure and a set of subplots for out-of-time data\n",
    "fig, ax3 = plt.subplots()\n",
    "\n",
    "# Plot partial dependence plot on the primary y-axis using ootthree_x_filtered\n",
    "display_oot = PartialDependenceDisplay.from_estimator(\n",
    "    model, ootthree_x_filtered, features=[feature_name], ax=ax3, line_kw={\"label\": \"Out-of-Time3\", \"color\": \"green\"}\n",
    ")\n",
    "\n",
    "# Set the primary y-axis to start at 0\n",
    "ax3.set_ylim(bottom=0)\n",
    "\n",
    "# Create a secondary y-axis for frequency values\n",
    "ax4 = ax3.twinx()\n",
    "\n",
    "# Plot histogram on the secondary y-axis (frequency values)\n",
    "ax4.hist(ootthree_x_filtered[feature_name], bins=30, alpha=0.5, color='grey')\n",
    "\n",
    "# Set labels for the axes\n",
    "ax3.set_ylabel('Partial Dependence')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax3.set_xlabel(f\"{feature_name} Value\")\n",
    "\n",
    "# Customize the plot (optional)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834c93c",
   "metadata": {},
   "source": [
    "**Feature and Permutation Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26595be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "# Plot feature importance\n",
    "ax = lgb.plot_importance(model, importance_type='gain', max_num_features=25)\n",
    "ax.figure.tight_layout()\n",
    "\n",
    "# Extract the feature names and their importances from the plot\n",
    "top_features = [(ax.get_yticklabels()[i].get_text(), ax.patches[i].get_width()) for i in range(len(ax.get_yticklabels()))]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "top_features_df = pd.DataFrame(top_features, columns=['Feature', 'Importance'])\n",
    "\n",
    "# Print the top features with their importances\n",
    "print(top_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b063d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Plot feature importance using LightGBM\n",
    "ax = lgb.plot_importance(model, importance_type='gain', max_num_features=25)\n",
    "ax.figure.tight_layout()\n",
    "\n",
    "# Extract feature names and importance values from the matplotlib plot\n",
    "top_features = [(ax.get_yticklabels()[i].get_text(), ax.patches[i].get_width()) for i in range(len(ax.get_yticklabels()))]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "top_features_df = pd.DataFrame(top_features, columns=['Feature', 'Importance'])\n",
    "\n",
    "# Create a Plotly Express horizontal bar chart\n",
    "fig = px.bar(\n",
    "    top_features_df.sort_values(by='Importance'),\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    orientation='h',\n",
    "    title='Feature Importance',\n",
    "    labels={'Importance': 'Gain', 'Feature': 'Feature'}\n",
    ")\n",
    "\n",
    "fig.update_layout(width=700,yaxis=dict(tickfont=dict(size=10)))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701605ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import roc_curve, auc, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# Define a function to calculate the Gini coefficient using the ROC AUC\n",
    "def calculate_gini(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)  # Compute false positive and true positive rates\n",
    "    roc_auc = auc(fpr, tpr)  # Calculate the area under the ROC curve\n",
    "    return roc_auc * 2 - 1  # Convert AUC to Gini coefficient\n",
    "# Wrap the Gini calculation in a scorer function\n",
    "def gini_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)[:, 1]  # Get the predicted probabilities for the positive class\n",
    "    return calculate_gini(y, y_pred)\n",
    "\n",
    "# Define and configure a LightGBM model\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "\n",
    "# Compute permutation feature importance using the custom Gini scorer\n",
    "result = permutation_importance(\n",
    "    model,\n",
    "    ho_x_final,\n",
    "    ho_y,\n",
    "    n_repeats=30,  # Number of times to permute a feature\n",
    "    random_state=888,\n",
    "    scoring=gini_scorer\n",
    ")\n",
    "\n",
    "# Create a DataFrame to store feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': ho_x_final.columns,\n",
    "    'mean_importance': result.importances_mean,\n",
    "    'std_importance': result.importances_std\n",
    "}).sort_values(by='mean_importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances with error bars\n",
    "importance_df.plot(kind='barh', x='feature', y='mean_importance', xerr='std_importance', legend=False, figsize=(15, 10))\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()\n",
    "\n",
    "# Print the importance DataFrame and raw Gini importances\n",
    "print(importance_df)\n",
    "print(\"Gini Importances:\", result.importances_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800275f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333671a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Ensure importance_df is already defined and contains the correct columns\n",
    "fig = px.bar(\n",
    "    importance_df,\n",
    "    x='mean_importance',\n",
    "    y='feature',\n",
    "    error_x='std_importance',\n",
    "    orientation='h',\n",
    "    title='Permutation Feature Importance (Gini)',\n",
    "    labels={'mean_importance': 'Mean Importance', 'feature': 'Feature'}\n",
    ")\n",
    "\n",
    "# Reverse the y-axis to show highest importance at the top\n",
    "fig.update_layout(width=800, yaxis=dict(autorange='reversed'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb44f53",
   "metadata": {},
   "source": [
    "**SHAP Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "# if you have an x_test set you can put it in explainer () like so\n",
    "shap_values = explainer(dev_x_final)\n",
    "\n",
    "# Initialize the SHAP JavaScript library\n",
    "shap.initjs()\n",
    "\n",
    "# Get the names of the features\n",
    "feature_names = dev_x_final.columns.tolist()\n",
    "\n",
    "# Get SHAP values for a specific instance (record 888)\n",
    "shap_values_instance = shap_values[8888]\n",
    "\n",
    "# Plot the waterfall plot\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=shap_values_instance.values,\n",
    "        base_values=shap_values_instance.base_values,\n",
    "        data=shap_values_instance.data,\n",
    "        feature_names=feature_names\n",
    "    ),\n",
    "    max_display=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1059ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define your model here\n",
    "# model = ...\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "# if you have an x_test set you can put it in explainer () like so\n",
    "shap_values = explainer(dev_x_final)\n",
    "\n",
    "# Initialize the SHAP JavaScript library\n",
    "shap.initjs()\n",
    "\n",
    "# Get the names of the features\n",
    "feature_names = dev_x_final.columns.tolist()\n",
    "\n",
    "# Get SHAP values for a specific instance (record 888)\n",
    "shap_values_instance = shap_values[888]\n",
    "\n",
    "# Check the original SHAP values to ensure they are not zeros\n",
    "print(\"Original SHAP values:\", shap_values_instance.values)\n",
    "\n",
    "# Scale the SHAP values to make them more visible\n",
    "scaling_factor = 1e1\n",
    "scaled_shap_values = shap_values_instance.values * scaling_factor\n",
    "\n",
    "# Plot the waterfall plot with scaled values\n",
    "shap.waterfall_plot(\n",
    "    shap.Explanation(\n",
    "        values=scaled_shap_values,\n",
    "        base_values=shap_values_instance.base_values * scaling_factor,\n",
    "        data=shap_values_instance.data,\n",
    "        feature_names=feature_names\n",
    "    ),\n",
    "    max_display=25,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "# Increase the number of decimal places displayed in the SHAP waterfall plot\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.6f}'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d20deb",
   "metadata": {},
   "source": [
    "**Plot SHAP Beeswarm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca60cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(dev_x_final)\n",
    "\n",
    "\n",
    "# Create a SHAP Explanation object\n",
    "shap_values_object = shap.Explanation(\n",
    "values=shap_values.values,\n",
    "base_values=shap_values.base_values,\n",
    "data=dev_x_final,\n",
    "feature_names=dev_x_final.columns\n",
    ")\n",
    "\n",
    "# Create a summary plot (beeswarm plot)\n",
    "shap.summary_plot(shap_values_object, max_display=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35781e4",
   "metadata": {},
   "source": [
    "**Prepare Data for Gini Analyses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "date_dev = df_dev[~df_dev['yourGBflag'].isin([\"I\"])][['date', 'GBF']]\n",
    "date_oottwo = df_oottwo[~df_oottwo['yourGBflag'].isin([\"I\"])][['date', 'GBF']]\n",
    "date_ootthree = df_ootthree [~df_ootthree ['yourGBflag'].isin([\"I\"])][['date', 'GBF']]\n",
    "date_ho = df_ho[~df_ho['yourGBflag'].isin([\"I\"])][['date', 'GBF']]\n",
    "\n",
    "\n",
    "\n",
    "date_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91168a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=dev_x_final.join(date_dev)\n",
    "oottwo=oottwo_x_final.join(date_oottwo)\n",
    "ootthree=ootthree_x_final.join(date_ootthree)\n",
    "ho=ho_x_final.join(date_ho)\n",
    "\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7543c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "oottwo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "97200758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f3c218cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.10.4'"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install --upgrade nbformat\n",
    "import nbformat\n",
    "nbformat.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install duckdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e751b",
   "metadata": {},
   "source": [
    "**Gini over Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.express as px\n",
    "import duckdb\n",
    "\n",
    "# Function to calculate Gini coefficient for a given month\n",
    "def calculate_gini(data, model):\n",
    "    x = data.drop(['GBF', 'date'], axis=1)\n",
    "    y = data['GBF']\n",
    "    probs = model.predict(x)\n",
    "    if probs.ndim > 1:\n",
    "        probs = probs[:, 1]  # Use the probabilities for the positive class\n",
    "    fpr, tpr, _ = roc_curve(y, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc * 2 - 1\n",
    "\n",
    "# Function to calculate Gini over time\n",
    "def gini_over_time(data, model):\n",
    "    unique_months = data['date'].unique()\n",
    "    gini_scores = []\n",
    "    \n",
    "    for month in unique_months:\n",
    "        monthly_data = data[data['date'] == month]\n",
    "        gini_score = calculate_gini(monthly_data, model)\n",
    "        gini_scores.append((month, gini_score))\n",
    "    \n",
    "    return gini_scores\n",
    "\n",
    "# Calculate Gini over time for each dataset\n",
    "gini_dev = gini_over_time(dev, model)\n",
    "gini_ho = gini_over_time(ho, model)\n",
    "gini_oottwo = gini_over_time(oottwo, model)\n",
    "gini_ootthree = gini_over_time(ootthree, model)\n",
    "\n",
    "# Convert Gini scores to DataFrame for plotting\n",
    "gini_dev_df = pd.DataFrame(gini_dev, columns=['Month', 'Gini'])\n",
    "gini_ho_df = pd.DataFrame(gini_ho, columns=['Month', 'Gini'])\n",
    "gini_oottwo_df = pd.DataFrame(gini_oottwo, columns=['Month', 'Gini'])\n",
    "gini_ootthree_df = pd.DataFrame(gini_ootthree, columns=['Month', 'Gini'])\n",
    "\n",
    "# Print the DataFrames to check the values\n",
    "print(\"Gini Dev DataFrame:\\n\", gini_dev_df)\n",
    "print(\"Gini HO DataFrame:\\n\", gini_ho_df)\n",
    "print(\"Gini OOT Two DataFrame:\\n\", gini_oottwo_df)\n",
    "print(\"Gini OOT Three DataFrame:\\n\", gini_ootthree_df)\n",
    "\n",
    "# Order DataFrames by Month using DuckDB\n",
    "gini_dev_df = duckdb.query('SELECT * FROM gini_dev_df ORDER BY Month').df()\n",
    "gini_ho_df = duckdb.query('SELECT * FROM gini_ho_df ORDER BY Month').df()\n",
    "gini_oottwo_df = duckdb.query('SELECT * FROM gini_oottwo_df ORDER BY Month').df()\n",
    "gini_ootthree_df = duckdb.query('SELECT * FROM gini_ootthree_df ORDER BY Month').df()\n",
    "\n",
    "# Convert Month to datetime\n",
    "gini_dev_df['Month'] = pd.to_datetime(gini_dev_df['Month'], format='%Y%m')\n",
    "gini_ho_df['Month'] = pd.to_datetime(gini_ho_df['Month'], format='%Y%m')\n",
    "gini_oottwo_df['Month'] = pd.to_datetime(gini_oottwo_df['Month'], format='%Y%m')\n",
    "gini_ootthree_df['Month'] = pd.to_datetime(gini_ootthree_df['Month'], format='%Y%m')\n",
    "\n",
    "# Combine the DataFrames into one\n",
    "gini_dev_df['Dataset'] = 'Development'\n",
    "gini_ho_df['Dataset'] = 'Holdout'\n",
    "gini_oottwo_df['Dataset'] = 'Out of Time2'\n",
    "gini_ootthree_df['Dataset'] = 'Out of Time3'\n",
    "\n",
    "combined_df = pd.concat([gini_dev_df, gini_ho_df, gini_oottwo_df, gini_ootthree_df])\n",
    "\n",
    "# Print the combined DataFrame to check the values\n",
    "print(\"Combined DataFrame:\\n\", combined_df)\n",
    "\n",
    "# Plot the lines by name using Plotly Express\n",
    "fig = px.line(combined_df, x='Month', y='Gini', color='Dataset', title='Gini Coefficient Over Time', labels={'Gini': 'Gini Coefficient'})\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Gini Coefficient',\n",
    "    legend_title='Dataset',\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[0, 1.0])\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b502511",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbe33f",
   "metadata": {},
   "source": [
    "**Gini per Feature for Dev, Hld and OoT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    " \n",
    "# === Gini Calculation ===\n",
    "def calculate_gini(y_true, y_pred_proba):\n",
    "    \"\"\"Calculate Gini coefficient from predicted probabilities.\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return 2 * roc_auc - 1\n",
    "\n",
    "# === Gini Evaluation Function ===\n",
    "def evaluate_gini(X, y, model):\n",
    "    \"\"\"Evaluate Gini coefficient on a dataset.\"\"\"\n",
    "    probs = model.predict_proba(X)[:, 1]  # Probability of class 1\n",
    "    return calculate_gini(y, probs)\n",
    "# === Main program ==\n",
    "def gini_checking_with_return(var,dev,ho,oot,oot3):\n",
    "    import pandas as pd\n",
    "    import re\n",
    " \n",
    "    # Fill missing values\n",
    "    ho = ho.fillna(value=-999999999)\n",
    "    dev = dev.fillna(value=-999999999)\n",
    "    oot = oot.fillna(value=-999999999)\n",
    "    oot3 = oot3.fillna(value=-999999999)\n",
    " \n",
    "    \n",
    "    ho = ho[[var, 'GBF']].copy()\n",
    "    oot = oot[[var, 'GBF']].copy()\n",
    "    dev = dev[[var, 'GBF']].copy()\n",
    "    oot3 = oot3[[var, 'GBF']].copy()\n",
    "   \n",
    " \n",
    "    # Prepare data\n",
    "    dev_x = dev[[var]]\n",
    "    ho_x = ho[[var]]\n",
    "    oot_x = oot[[var]]\n",
    "    oot3_x = oot3[[var]]\n",
    " \n",
    "    dev_y = dev['GBF']\n",
    "    ho_y = ho['GBF']\n",
    "    oot_y = oot['GBF']\n",
    "    oot3_y = oot3['GBF']\n",
    " \n",
    "    # Train model\n",
    "    model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    " \n",
    "    model.fit(\n",
    "        dev_x,\n",
    "        dev_y,\n",
    "        eval_set=[(ho_x, ho_y)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    "    )\n",
    "    \n",
    " \n",
    "    # Evaluate Gini\n",
    "    gini_dev = evaluate_gini(dev_x, dev_y, model)\n",
    "    gini_holdout = evaluate_gini(ho_x, ho_y, model)\n",
    "    gini_oot = evaluate_gini(oot_x, oot_y, model)\n",
    "    gini_oot3 = evaluate_gini(oot3_x, oot3_y, model)\n",
    " \n",
    "    return gini_dev, gini_holdout, gini_oot, gini_oot3\n",
    " \n",
    "# === Loop through variables and collect Gini scores ===\n",
    "var_gini = pd.DataFrame(columns=['Variable', 'Dev_Gini', 'Holdout_Gini', 'OOT2_Gini','OOT3_Gini'])\n",
    "columns_to_keep = [\n",
    "'feature1',\t'feature2',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature20'\n",
    "]\n",
    "for var in columns_to_keep:\n",
    "    try:\n",
    "        print(f\"Processing variable: {var}\")\n",
    "        gini_dev, gini_holdout, gini_oot,gini_oot3 = gini_checking_with_return(var,dev,ho,oot,oot3) #this is what I called my datasets\n",
    "        var_gini = pd.concat([var_gini, pd.DataFrame([{\n",
    "            'Variable': var,\n",
    "            'Dev_Gini': gini_dev,\n",
    "            'Holdout_Gini': gini_holdout,\n",
    "            'OOT2_Gini': gini_oot,\n",
    "            'OOT3_Gini': gini_oot3\n",
    "        }])], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var}: {e}\")\n",
    " \n",
    "# Display or save results\n",
    "print(\"\\nFinal Gini Scores:\")\n",
    "var_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b36137",
   "metadata": {},
   "source": [
    "**Ranking per Decile Dev, Hld, OoT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a35fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected dev\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "probs_dev = model.predict_proba(dev_x_final)[:, 1]\n",
    "probs_hld = model.predict_proba(ho_x_final)[:, 1]\n",
    "probs_oottwo = model.predict_proba(oottwo_x_final)[:, 1]\n",
    "probs_ootthree = model.predict_proba(ootthree_x_final)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_ae=dev_x_final.copy() \n",
    "df_ae[\"probs_dev\"] = model.predict_proba(dev_x_final)[:, 1]\n",
    "df_ae[\"target\"]=dev_y\n",
    "\n",
    "\n",
    "df_ae.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a0948056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae['qtile'] = pd.qcut(df_ae.probs_dev, q=10, labels=False) #dividing df into percentiles - choose another value for q if there are not 100 or more unique probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a576b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = df_ae.groupby('qtile',as_index=False).target.sum()\n",
    "df_temp2 = df_ae.groupby('qtile',as_index=False).size()\n",
    "df_temp2_1 = df_ae.groupby('qtile',as_index=False).probs_dev.mean()\n",
    "df_temp3 = pd.merge(df_temp1,df_temp2)\n",
    "df_temp3['event_rate'] = df_temp3['target']/df_temp3['size']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f48fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp3_1 = pd.merge(df_temp3,df_temp2_1)\n",
    "df_temp3_1['Prob'] = df_temp3_1['probs_dev']*100\n",
    "df_temp3_1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30271f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected oot2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_ae_oot2=oottwo_x_final.copy() \n",
    "df_ae_oot2[\"probs_oot2\"] = model.predict_proba(oottwo_x_final)[:, 1]\n",
    "df_ae_oot2[\"target\"]=oottwo_y\n",
    "\n",
    "\n",
    "df_ae_oot2.head()\n",
    "\n",
    "df_ae_oot2['qtile'] = pd.qcut(df_ae_oot2.probs_oot2, q=10, labels=False)\n",
    "df_temp1 = df_ae_oot2.groupby('qtile',as_index=False).target.sum()\n",
    "df_temp2 = df_ae_oot2.groupby('qtile',as_index=False).size()\n",
    "df_temp2_1 = df_ae_oot2.groupby('qtile',as_index=False).probs_oot2.mean()\n",
    "df_temp3 = pd.merge(df_temp1,df_temp2)\n",
    "df_temp3['event_rate'] = df_temp3['target']/df_temp3['size']*100\n",
    "df_temp3_1 = pd.merge(df_temp3,df_temp2_1)\n",
    "df_temp3_1['Prob'] = df_temp3_1['probs_oot2']*100\n",
    "df_temp3_1.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected oot3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_ae_oot3=ootthree_x_final.copy() \n",
    "df_ae_oot3[\"probs_oot3\"]=model.predict_proba(ootthree_x_final)[:, 1]\n",
    "df_ae_oot3[\"target\"]=ootthree_y\n",
    "\n",
    "\n",
    "df_ae_oot3.head()\n",
    "\n",
    "df_ae_oot3['qtile'] = pd.qcut(df_ae_oot3.probs_oot3, q=10, labels=False)\n",
    "df_temp1 = df_ae_oot3.groupby('qtile',as_index=False).target.sum()\n",
    "df_temp2 = df_ae_oot3.groupby('qtile',as_index=False).size()\n",
    "df_temp2_1 = df_ae_oot3.groupby('qtile',as_index=False).probs_oot3.mean()\n",
    "df_temp3 = pd.merge(df_temp1,df_temp2)\n",
    "df_temp3['event_rate'] = df_temp3['target']/df_temp3['size']*100\n",
    "df_temp3_1 = pd.merge(df_temp3,df_temp2_1)\n",
    "df_temp3_1['Prob'] = df_temp3_1['probs_oot3']*100\n",
    "df_temp3_1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb55e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected ho\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_ae_ho=ho_x_final.copy() \n",
    "df_ae_ho[\"probs_ho\"] = model.predict_proba(ho_x_final)[:, 1]\n",
    "df_ae_ho[\"target\"]=ho_y\n",
    "\n",
    "\n",
    "df_ae_ho.head()\n",
    "\n",
    "df_ae_ho['qtile'] = pd.qcut(df_ae_ho.probs_ho, q=10, labels=False)\n",
    "df_temp1 = df_ae_ho.groupby('qtile',as_index=False).target.sum()\n",
    "df_temp2 = df_ae_ho.groupby('qtile',as_index=False).size()\n",
    "df_temp2_1 = df_ae_ho.groupby('qtile',as_index=False).probs_ho.mean()\n",
    "df_temp3 = pd.merge(df_temp1,df_temp2)\n",
    "df_temp3['event_rate'] = df_temp3['target']/df_temp3['size']*100\n",
    "df_temp3_1 = pd.merge(df_temp3,df_temp2_1)\n",
    "df_temp3_1['Prob'] = df_temp3_1['probs_ho']*100\n",
    "df_temp3_1.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828ed01",
   "metadata": {},
   "source": [
    "**Score Distribution Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_ae is your DataFrame\n",
    "df_ae['probs'] = df_ae['probs_dev'].round(5)\n",
    "\n",
    "# Group by 'probs' and calculate the mean of 'target' and count the occurrences\n",
    "result = df_ae.groupby('probs').agg(\n",
    " bads=('target', 'sum'),\n",
    " volume=('target', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by 'probs'\n",
    "result = result.sort_values(by='probs')\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected dev\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "probs_dev = model.predict_proba(dev_x_final)[:, 1]\n",
    "probs_hld = model.predict_proba(ho_x_final)[:, 1]\n",
    "probs_oottwo = model.predict_proba(oottwo_x_final)[:, 1]\n",
    "probs_ootthree = model.predict_proba(ootthree_x_final)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_ae=dev_x_final.copy() \n",
    "df_ae[\"probs_dev\"] = model.predict_proba(dev_x_final)[:, 1]\n",
    "df_ae[\"target\"]=dev_y\n",
    "\n",
    "\n",
    "df_ae.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3678f0",
   "metadata": {},
   "source": [
    "**Scale probs to a more Interpretable score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65058a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting_type='gbdt',\n",
    "    metric='auc',\n",
    "    learning_rate=0.001,\n",
    "    max_depth=10,\n",
    "    num_leaves=32,\n",
    "    min_data_in_leaf=500,\n",
    "    feature_fraction=0.3,\n",
    "    bagging_fraction=0.3,\n",
    "    min_child_samples=1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight=0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain=1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha=0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda=0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators=25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Function to scale predictions\n",
    "def scale_predictions(predictions, old_min, old_max, new_min, new_max):\n",
    "    \"\"\"\n",
    "    Scale the predictions from the old range to the new range.\n",
    "    \n",
    "    :param predictions: List or numpy array of predictions\n",
    "    :param old_min: Minimum value of the old range\n",
    "    :param old_max: Maximum value of the old range\n",
    "    :param new_min: Minimum value of the new range\n",
    "    :param new_max: Maximum value of the new range\n",
    "    :return: Scaled predictions\n",
    "    \"\"\"\n",
    "    scaled_predictions = ((predictions - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min\n",
    "    return scaled_predictions\n",
    "\n",
    "# Get and scale predictions for different datasets\n",
    "probs_dev = model.predict_proba(dev_x_final)[:, 1]\n",
    "probs_hld = model.predict_proba(ho_x_final)[:, 1]\n",
    "probs_oottwo = model.predict_proba(oottwo_x_final)[:, 1]\n",
    "probs_ootthree = model.predict_proba(ootthree_x_final)[:, 1]\n",
    "\n",
    "# Define the old and new ranges for scaling\n",
    "old_min = 0.04  # 4.0%\n",
    "old_max = 0.042  # 4.2%\n",
    "new_min = 450\n",
    "new_max = 750\n",
    "\n",
    "# Scale the predictions\n",
    "scaled_probs_dev = scale_predictions(probs_dev, old_min, old_max, new_min, new_max)\n",
    "scaled_probs_hld = scale_predictions(probs_hld, old_min, old_max, new_min, new_max)\n",
    "scaled_probs_oottwo = scale_predictions(probs_oottwo, old_min, old_max, new_min, new_max)\n",
    "scaled_probs_ootthree = scale_predictions(probs_ootthree, old_min, old_max, new_min, new_max)\n",
    "\n",
    "# Create a DataFrame with scaled predictions and targets for dev dataset\n",
    "df_ae = dev_x_final.copy()\n",
    "df_ae[\"scaled_probs_dev\"] = scaled_probs_dev\n",
    "df_ae[\"target\"] = dev_y\n",
    "\n",
    "df_ae.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8df44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def gini(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Gini coefficient based on true labels and predicted probabilities.\n",
    "    \n",
    "    :param y_true: List or numpy array of true labels\n",
    "    :param y_pred: List or numpy array of predicted probabilities\n",
    "    :return: Gini coefficient\n",
    "    \"\"\"\n",
    "    return 2 * roc_auc_score(y_true, y_pred) - 1\n",
    "\n",
    "# Calculate Gini coefficient for the scaled predictions\n",
    "gini_dev = gini(dev_y, scaled_probs_dev)\n",
    "gini_hld = gini(ho_y, scaled_probs_hld)\n",
    "gini_oottwo = gini(oottwo_y, scaled_probs_oottwo)\n",
    "gini_ootthree = gini(ootthree_y, scaled_probs_ootthree)\n",
    "\n",
    "print(f\"Gini coefficient for dev dataset: {gini_dev}\")\n",
    "print(f\"Gini coefficient for holdout dataset: {gini_hld}\")\n",
    "print(f\"Gini coefficient for out-of-time two dataset: {gini_oottwo}\")\n",
    "print(f\"Gini coefficient for out-of-time three dataset: {gini_ootthree}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4e7b1",
   "metadata": {},
   "source": [
    "**Overall PSI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bade8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "df_rec=pd.read_csv ('/location/rec.csv',low_memory=False)\n",
    "pd.set_option('display.max_column',None)\n",
    "\n",
    "\n",
    "df_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stability analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Load the model from the pickle file\n",
    "#with open('lightgbm_model_Owen.pkl', 'rb') as file:\n",
    "   # model = pickle.load(file)\n",
    "#Import datasets, each has all the features, date and target(y) in them\n",
    "ho=ho_x_final\n",
    "oot=oottwo_x_final\n",
    "dev=dev_x_final\n",
    "oot3=ootthree_x_final\n",
    "\n",
    "# Function to calculate psi using consistent binning from reference data\n",
    "def calculate_psi(data, model, reference_data):\n",
    "    x = data\n",
    "    scores = model.predict(x)\n",
    "\n",
    "    ref_x = reference_data\n",
    "    ref_scores = model.predict(ref_x)\n",
    "\n",
    "    # Get bin edges from reference scores\n",
    "    ref_bins, bin_edges = pd.qcut(ref_scores, q=10, retbins=True, duplicates='drop')\n",
    "\n",
    "    # Use the same bin edges for both datasets\n",
    "    ref_bin_labels = pd.cut(ref_scores, bins=bin_edges, include_lowest=True)\n",
    "    score_bin_labels = pd.cut(scores, bins=bin_edges, include_lowest=True)\n",
    "\n",
    "    # Calculate proportions\n",
    "    ref_bin_counts = pd.value_counts(ref_bin_labels, normalize=True).sort_index()\n",
    "    bin_counts = pd.value_counts(score_bin_labels, normalize=True).sort_index()\n",
    "\n",
    "    # Align and calculate psi\n",
    "    ref_bin_counts, bin_counts = ref_bin_counts.align(bin_counts, fill_value=1e-6)\n",
    "    psi = np.sum((bin_counts - ref_bin_counts) * np.log(bin_counts / ref_bin_counts))\n",
    "    print(\"Development Data Bands and Percentages:\")\n",
    "    print(ref_bin_counts)\n",
    "    \n",
    "    print(\"\\nCurrent Data Bands and Percentages:\")\n",
    "    print(bin_counts)\n",
    "    return psi\n",
    "\n",
    "\n",
    "\n",
    "# Calculate psi values\n",
    "print(\"Development Data:\")\n",
    "psi_dev = calculate_psi(dev, model, dev)\n",
    "print(\"Holdout Data:\")\n",
    "psi_ho = calculate_psi(ho, model, dev)\n",
    "print(\"Out-of-time Data:\")\n",
    "psi_oot = calculate_psi(oot, model, dev)\n",
    "print(\"Out-of-time3 Data:\")\n",
    "psi_oot3 = calculate_psi(oot3[dev.columns], model, dev)\n",
    "print(\"Recent Data:\")\n",
    "psi_rec = calculate_psi(rec[dev.columns], model, dev)\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "overall_psi_df = pd.DataFrame({\n",
    "    'Dataset': ['Development', 'Holdout', 'Out of Time', 'Out of Time3', 'Recent'],\n",
    "    'PSI': [psi_dev, psi_ho, psi_oot, psi_oot3, psi_rec]\n",
    "})\n",
    "\n",
    "\n",
    "# Assign colors based on psi thresholds\n",
    "def get_color(psi):\n",
    "    if psi < 0.1:\n",
    "        return 'green'\n",
    "    elif psi < 0.25:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'red'\n",
    "\n",
    "overall_psi_df['Color'] = overall_psi_df['PSI'].apply(get_color)\n",
    "\n",
    "# Plot using Plotly\n",
    "fig = px.bar(\n",
    "    overall_psi_df,\n",
    "    x='Dataset',\n",
    "    y='PSI',\n",
    "    text='PSI',\n",
    "    color='Color',\n",
    "    color_discrete_map='identity',\n",
    "    title='Overall PSI by Dataset'\n",
    ")\n",
    "upper_bound=overall_psi_df['PSI'].max()+0.1\n",
    "fig.update_layout(template='plotly_white', yaxis=dict(range=[0,upper_bound]))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497e313",
   "metadata": {},
   "source": [
    "**PSI Final Table - Haven't tested code yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_x_final=rec[dev.columns]\n",
    "rec_x_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "def calculate_psi(data, model, reference_data):\n",
    "    x = data\n",
    "    scores = model.predict(x)\n",
    " \n",
    "    ref_x = reference_data\n",
    "    ref_scores = model.predict(ref_x)\n",
    " \n",
    "    # Get bin edges from reference scores\n",
    "    ref_bins, bin_edges = pd.qcut(ref_scores, q=10, retbins=True, duplicates='drop')\n",
    " \n",
    "    # Use the same bin edges for both datasets\n",
    "    ref_bin_labels = pd.cut(ref_scores, bins=bin_edges, include_lowest=True)\n",
    "    score_bin_labels = pd.cut(scores, bins=bin_edges, include_lowest=True)\n",
    " \n",
    "    # Calculate proportions\n",
    "    ref_bin_counts = pd.value_counts(ref_bin_labels, normalize=True).sort_index()\n",
    "    bin_counts = pd.value_counts(score_bin_labels, normalize=True).sort_index()\n",
    " \n",
    "    # Align and calculate psi\n",
    "    ref_bin_counts, bin_counts = ref_bin_counts.align(bin_counts, fill_value=1e-6)\n",
    "    psi = np.sum((bin_counts - ref_bin_counts) * np.log(bin_counts / ref_bin_counts))\n",
    "    print(\"Development Data Bands and Percentages:\")\n",
    "    print(ref_bin_counts)\n",
    "    print(\"\\nCurrent Data Bands and Percentages:\")\n",
    "    print(bin_counts)\n",
    "    return psi,bin_counts\n",
    " \n",
    " \n",
    "# Calculate psi values\n",
    "print(\"Development Data:\")\n",
    "psi_dev,dev_bins = calculate_psi(dev_x_final, model, dev_x_final)\n",
    "print(\"Holdout Data:\")\n",
    "psi_ho,ho_bins= calculate_psi(ho_x_final, model, dev_x_final)\n",
    "# print(\"Out-of-time Data:\")\n",
    "# psi_oot = calculate_psi(oot, model, dev)\n",
    "# print(\"Out-of-time3 Data:\")\n",
    "# psi_oot3 = calculate_psi(oot3[dev.columns], model, dev)\n",
    "print(\"Recent Data:\")\n",
    "psi_rec,rec_bins = calculate_psi(rec_x_final, model, dev_x_final)\n",
    "\n",
    "\n",
    "# Assuming dev_bins, ho_bins, and rec_bins are dictionaries or Series\n",
    "bins_df = pd.DataFrame({\n",
    "    'dev_bins_index': pd.Series(dev_bins.index),\n",
    "    'dev_bins_share': pd.Series(dev_bins.values),\n",
    "    'ho_bins_share': pd.Series(ho_bins.values),\n",
    "    'rec_bins_share': pd.Series(rec_bins.values)\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "overall_psi_df = pd.DataFrame({\n",
    "    'Dataset': ['Development', 'Holdout','Recent'],\n",
    "    'PSI': [psi_dev, psi_ho,psi_rec]\n",
    "})\n",
    " \n",
    " \n",
    "# Assign colors based on psi thresholds\n",
    "def get_color(psi):\n",
    "    if psi < 0.1:\n",
    "        return 'green'\n",
    "    elif psi < 0.25:\n",
    "        return 'orange'\n",
    "    else:\n",
    "        return 'red'\n",
    " \n",
    "overall_psi_df['Color'] = overall_psi_df['PSI'].apply(get_color)\n",
    " \n",
    "# Plot using Plotly\n",
    "fig = px.bar(\n",
    "    overall_psi_df,\n",
    "    x='Dataset',\n",
    "    y='PSI',\n",
    "    text='PSI',\n",
    "    color='Color',\n",
    "    color_discrete_map='identity',\n",
    "    title='Overall PSI by Dataset'\n",
    ")\n",
    "upper_bound=overall_psi_df['PSI'].max()+0.1\n",
    "fig.update_layout(template='plotly_white', yaxis=dict(range=[0,upper_bound]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca47153",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d3a19",
   "metadata": {},
   "source": [
    "**CSI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9403c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Import datasets, each has all the features, date and target(y) in them\n",
    "ho=ho_x_final\n",
    "oot=ootthree_x_final\n",
    "dev=dev_x_final\n",
    "\n",
    "# Function to calculate CSI for a specific feature\n",
    "def calculate_feature_csi(data, feature, reference_data):\n",
    "    # Bin the feature values in the reference data\n",
    "    ref_bins, bin_edges = pd.qcut(reference_data[feature], q=4, retbins=True, duplicates='drop')\n",
    "\n",
    "    # Calculate proportions in each bin for the reference data\n",
    "    ref_bin_labels = pd.cut(reference_data[feature], bins=bin_edges, include_lowest=True)\n",
    "    ref_bin_counts = pd.value_counts(ref_bin_labels, normalize=True).sort_index()\n",
    "\n",
    "    # Apply the same bin edges to the current data\n",
    "    bin_labels = pd.cut(data[feature], bins=bin_edges, include_lowest=True)\n",
    "    bin_counts = pd.value_counts(bin_labels, normalize=True).sort_index()\n",
    "\n",
    "    # Align and calculate CSI\n",
    "    ref_bin_counts, bin_counts = ref_bin_counts.align(bin_counts, fill_value=1e-6)\n",
    "    csi = np.sum((bin_counts - ref_bin_counts) * np.log(bin_counts / ref_bin_counts))\n",
    "\n",
    "    return csi\n",
    "\n",
    "# Function to calculate CSI for all features and generate a color-coded table\n",
    "def generate_feature_csi_table(data, reference_data):\n",
    "    features = data.columns\n",
    "    csi_values = []\n",
    "\n",
    "    for feature in features:\n",
    "        csi_dev = calculate_feature_csi(dev, feature, dev)\n",
    "        csi_ho = calculate_feature_csi(ho, feature, dev)\n",
    "        csi_oot = calculate_feature_csi(oot, feature, dev)\n",
    "        csi_rec = calculate_feature_csi(rec, feature, dev)\n",
    "\n",
    "        csi_values.append({\n",
    "            'Feature': feature,\n",
    "            'CSI in Dev': csi_dev,\n",
    "            'CSI in Holdout': csi_ho,\n",
    "            'CSI in OOT': csi_oot,\n",
    "            'CSI in Rec': csi_rec\n",
    "        })\n",
    "\n",
    "    # Create DataFrame for visualization\n",
    "    csi_df = pd.DataFrame(csi_values)\n",
    "\n",
    "    # Assign colors based on CSI thresholds\n",
    "    def get_color(csi):\n",
    "        if csi < 0.1:\n",
    "            return 'background-color: green'\n",
    "        elif csi < 0.25:\n",
    "            return 'background-color: orange'\n",
    "        else:\n",
    "            return 'background-color: red'\n",
    "\n",
    "    # Apply color coding to the DataFrame\n",
    "    styled_df = csi_df.style.applymap(get_color, subset=['CSI in Dev', 'CSI in Holdout', 'CSI in OOT', 'CSI in Rec'])\n",
    "\n",
    "    # Display the color-coded table\n",
    "    display(HTML(styled_df.to_html()))\n",
    "\n",
    "# Generate and display the color-coded table for feature stability index\n",
    "generate_feature_csi_table(dev, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1b0fd",
   "metadata": {},
   "source": [
    "**Cumulative Score Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc771f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep =[\t'feature1',\t'feature2',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature20']\n",
    "rec_final = rec.loc[:,columns_to_keep]\n",
    "\n",
    "rec_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "\n",
    "df_ae_rec=rec_final.copy() \n",
    "df_ae_rec[\"probs_rec\"] = model.predict_proba(rec_final)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9177eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Assuming df_ae is your DataFrame\n",
    "df_ae_dev['probs'] = df_ae_dev['probs_dev'].round(4)\n",
    "\n",
    "# Group by 'probs' and calculate the mean of 'target' and count the occurrences\n",
    "result_dev = df_ae_dev.groupby('probs').agg(\n",
    " volume_dev=('probs', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by 'probs'\n",
    "result_dev = result_dev.sort_values(by='probs')\n",
    "\n",
    "\n",
    "# Display the result\n",
    "result_dev.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_ae is your DataFrame\n",
    "df_ae_rec['probs'] = df_ae_rec['probs_rec'].round(4)\n",
    "\n",
    "# Group by 'probs' and calculate the mean of 'target' and count the occurrences\n",
    "result = df_ae_rec.groupby('probs').agg(\n",
    " volume_rec=('probs', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by 'probs'\n",
    "result_rec = result.sort_values(by='probs')\n",
    "\n",
    "\n",
    "# Display the result\n",
    "result_rec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Performing an outer join on the 'probs' column\n",
    "joined = pd.merge(result_dev, result_rec, on='probs', how='outer')\n",
    "\n",
    "print(joined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74a903",
   "metadata": {},
   "source": [
    "**Bias Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop indeterminates and columns not used as predictive features or the target\n",
    "\n",
    "bias1=df_dev[df_dev[\"yourGBflag\"] != \"I\"].drop(columns=['feature21','feature22', 'feature23', 'date', 'yourGBflag'])\n",
    "\n",
    "\n",
    "\n",
    "bias1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3069219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep =['feature1',\t'feature2',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature20']\n",
    "bias3 = bias1.loc[:,columns_to_keep]\n",
    "\n",
    "bias3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected dev\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the LightGBM classifier with correct parameters\n",
    "model = lgb.LGBMClassifier(\n",
    "    objective= 'binary',\n",
    "    boosting_type= 'gbdt',\n",
    "    metric= 'auc',\n",
    "    learning_rate= 0.001,\n",
    "    max_depth= 10,\n",
    "    num_leaves= 32,\n",
    "    min_data_in_leaf =500,\n",
    "    feature_fraction= 0.3,\n",
    "    bagging_fraction= 0.3,\n",
    "    min_child_samples= 1000,  # Minimum number of data in one leaf (regularization parameter)\n",
    "    min_child_weight= 0.1,  # Minimum sum of instance Hessian to make a child (regularization parameter)\n",
    "    min_split_gain= 1.0,  # Minimum loss reduction to make a split (regularization parameter)\n",
    "    reg_alpha= 0.01,  # L1 regularization term (regularization parameter)\n",
    "    reg_lambda= 0.01,  # L2 regularization term (regularization parameter)\n",
    "    n_estimators= 25  # Number of boosting rounds\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Get predictions\n",
    "\n",
    "bias3[\"probs_dev\"] = model.predict_proba(bias3)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "bias3.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep =['GBF',\t'Race',\t'Gender']\n",
    "bias_y = bias1.loc[:,columns_to_keep]\n",
    "\n",
    "bias_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined = bias3.join(bias_y, how='outer')\n",
    "\n",
    "joined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep =['GBF',\t'Race',\t 'probs_dev']\n",
    "joined2 = joined.loc[:,columns_to_keep]\n",
    "\n",
    "joined2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Handle missing values in the 'Race' column\n",
    "joined2['Race'].fillna('Mis', inplace=True)  # Example: filling NaNs with 'Unknown'\n",
    "\n",
    "# Check for NaN values in 'probs_dev' and handle them\n",
    "if joined2['probs_dev'].isnull().any():\n",
    "    joined2['probs_dev'].fillna(joined2['probs_dev'].mean(), inplace=True)  # Example: filling NaNs with the mean\n",
    "\n",
    "# Apply qcut with duplicates='drop' to handle duplicate bin edges\n",
    "joined2['qtile'] = pd.qcut(joined2['probs_dev'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "joined2.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ffd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Group by 'qtile' and 'Race', then calculate the sum of 'GBF' and count the number of rows\n",
    "race_df = joined2.groupby(['qtile', 'Race'], as_index=False).agg(\n",
    "    bads=('GBF', 'sum'),\n",
    "    vol=('GBF', 'count')\n",
    ")\n",
    "\n",
    "race_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eef13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns_to_keep =['GBF',\t'Gender',\t 'probs_dev']\n",
    "joined2 = joined.loc[:,columns_to_keep]\n",
    "\n",
    "\n",
    "# Handle missing values in the 'Race' column\n",
    "joined2['Gender'].fillna('Mis', inplace=True)  # Example: filling NaNs with 'Unknown'\n",
    "\n",
    "# Check for NaN values in 'probs_dev' and handle them\n",
    "if joined2['probs_dev'].isnull().any():\n",
    "    joined2['probs_dev'].fillna(joined2['probs_dev'].mean(), inplace=True)  # Example: filling NaNs with the mean\n",
    "\n",
    "# Apply qcut with duplicates='drop' to handle duplicate bin edges\n",
    "joined2['qtile'] = pd.qcut(joined2['probs_dev'], q=10, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "gen_df = joined2.groupby(['qtile', 'Gender'], as_index=False).agg(\n",
    "    bads=('GBF', 'sum'),\n",
    "    vol=('GBF', 'count')\n",
    ")\n",
    "\n",
    "gen_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50771bf7",
   "metadata": {},
   "source": [
    "**Visualisation of the Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ea1ef",
   "metadata": {},
   "source": [
    "**Only supertree worked and I wasn't able to customize the view like add bad rate per leaf and see exactly at which value it splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc17a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install supertree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8229aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install --upgrade supertree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supertree as st\n",
    "\n",
    "# Assuming you have a trained model named 'model'\n",
    "feature_names = ['feature1',\t'feature2',\t'feature5',\t'feature6',\t'feature7',\t'feature8',\t'feature9',\t'feature10',\t'feature11',\t'feature15',\t'feature16',\t'feature17',\t'feature18',\t'feature20']\n",
    "class_names = ['0', '1']  # Binary target classes\n",
    "\n",
    "# Convert target to list if necessary\n",
    "dev_y = dev_y.tolist()\n",
    "\n",
    "super_tree = st.SuperTree(model, dev_x_final, dev_y, feature_names, class_names)\n",
    "super_tree.show_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dtreeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a57df",
   "metadata": {},
   "source": [
    "**Actual vs Expected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbf8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate actual versus expected dev\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_ae_dev=dev_x_final.copy() \n",
    "df_ae_dev[\"probs_dev\"] = model.predict_proba(dev_x_final)[:, 1]\n",
    "df_ae_dev[\"target\"]=dev_y\n",
    "\n",
    "\n",
    "df_ae_dev.head()\n",
    "\n",
    "df_ae_dev['qtile'] = pd.qcut(df_ae_dev.probs_dev, q=10, labels=False)\n",
    "df_temp1 = df_ae_dev.groupby('qtile',as_index=False).target.sum()\n",
    "df_temp2 = df_ae_dev.groupby('qtile',as_index=False).size()\n",
    "df_temp2_1 = df_ae_dev.groupby('qtile',as_index=False).probs_dev.mean()\n",
    "df_temp3 = pd.merge(df_temp1,df_temp2)\n",
    "df_temp3['event_rate'] = df_temp3['target']/df_temp3['size']*100\n",
    "df_temp3_1 = pd.merge(df_temp3,df_temp2_1)\n",
    "df_temp3_1['Prob'] = df_temp3_1['probs_dev']*100\n",
    "df_temp3_1.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65090a83",
   "metadata": {},
   "source": [
    "**Other Boosting Algorithms for Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb17663",
   "metadata": {},
   "source": [
    "**Catboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b841ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catmodel = CatBoostClassifier(\n",
    "    loss_function='Logloss',         # Equivalent to binary classification\n",
    "    eval_metric='AUC',               # Same as LightGBM/XGBoost\n",
    "    learning_rate=0.001,\n",
    "    depth=10,                        # Equivalent to max_depth\n",
    "    l2_leaf_reg=0.01,                # Equivalent to reg_lambda (L2 regularization)\n",
    "    random_strength=0.01,            # Roughly similar to reg_alpha (L1 regularization)\n",
    "    iterations=10000,                # Large number to allow early stopping to kick in\n",
    "    early_stopping_rounds=5,         # Same as LightGBM/XGBoost\n",
    "    verbose=100,                     # Controls logging frequency\n",
    "    grow_policy='Depthwise',         # Matches LightGBM's depth-wise growth\n",
    "    min_data_in_leaf=500,           # Same as LightGBM\n",
    "    subsample=0.3,                   # Equivalent to bagging_fraction\n",
    "    rsm=0.3                          # Equivalent to feature_fraction (Random Subspace Method)\n",
    ")\n",
    "catmodel.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    "    eval_set=[(ho_x_final, ho_y)],  # Validation data\n",
    "    # Must match what you want to monitor\n",
    "  # Same as LightGBM's stopping_rounds\n",
    "    verbose=True          # Optional: shows progress\n",
    ")\n",
    "\n",
    "gini_score = evaluate_gini(dev_x_final, dev_y, catmodel)\n",
    "print(f\"Gini Score on dev set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ho_x_final, ho_y, catmodel)\n",
    "print(f\"Gini Score on ho set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ootthree_x_final, ootthree_y, catmodel)\n",
    "print(f\"Gini Score on oot3 set: {gini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bd501",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e277596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(\n",
    "    criterion='log_loss',\n",
    "    ccp_alpha=0.001,\n",
    "    max_depth=13,              # Matches LGBM's max_depth\n",
    "    min_samples_leaf=1300,      # Equivalent to min_data_in_leaf\n",
    "    min_weight_fraction_leaf=0.05,  # No direct match for min_child_weight, but this is closest\n",
    "    min_impurity_decrease=0.00010, # Equivalent to min_split_gain\n",
    "    class_weight='balanced',    # Helps with imbalanced data\n",
    "max_features=10)\n",
    "tree.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    ")\n",
    "gini_score = evaluate_gini(dev_x_final, dev_y, tree)\n",
    "print(f\"Gini Score on dev set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ho_x_final, ho_y, tree)\n",
    "print(f\"Gini Score on ho set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ootthree_x_final, ootthree_y, tree)\n",
    "print(f\"Gini Score on oot3 set: {gini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34d03c",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8974be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = RandomForestClassifier(\n",
    "    n_estimators=25,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=10,\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "RFmodel.fit(dev_x_final, dev_y)\n",
    "\n",
    "\n",
    "gini_score = evaluate_gini(dev_x_final, dev_y, RFmodel)\n",
    "print(f\"Gini Score on dev set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ho_x_final, ho_y, RFmodel)\n",
    "print(f\"Gini Score on ho set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ootthree_x_final, ootthree_y, RFmodel)\n",
    "print(f\"Gini Score on oot3 set: {gini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c66090",
   "metadata": {},
   "source": [
    "**Adaboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4200a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# AdaBoost classifier\n",
    "adaboost = AdaBoostClassifier(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Pipeline to handle missing values and train the model\n",
    "model_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values\n",
    "    ('classifier', adaboost)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "model_pipeline.fit(dev_x_final, dev_y)\n",
    "\n",
    "\n",
    "gini_score = evaluate_gini(dev_x_final, dev_y, model_pipeline)\n",
    "print(f\"Gini Score on dev set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ho_x_final, ho_y, model_pipeline)\n",
    "print(f\"Gini Score on ho set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ootthree_x_final, ootthree_y, model_pipeline)\n",
    "print(f\"Gini Score on oot3 set: {gini_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6297d0",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b36814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "xgbmodel = XGBClassifier(\n",
    "    colsample_bytree=0.3,\n",
    "    gamma=1.0,\n",
    "    learning_rate=0.001,\n",
    "    max_depth=10,\n",
    "    max_leaves=32,\n",
    "    min_child_weight=0.1,\n",
    "    missing=np.nan,\n",
    "    n_estimators=25,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "\n",
    "xgbmodel.fit(\n",
    "    dev_x_final,          # Training features\n",
    "    dev_y,                # Training labels\n",
    ")\n",
    "\n",
    "gini_score = evaluate_gini(dev_x_final, dev_y, xgbmodel)\n",
    "print(f\"Gini Score on dev set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ho_x_final, ho_y, xgbmodel)\n",
    "print(f\"Gini Score on ho set: {gini_score:.2f}\")\n",
    "gini_score = evaluate_gini(ootthree_x_final, ootthree_y, xgbmodel)\n",
    "print(f\"Gini Score on oot3 set: {gini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18584678",
   "metadata": {},
   "source": [
    "**Actual vs Expected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a6bea873",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_exp = df_ae_dev.groupby('qtile').agg(\n",
    "    bads=('target', 'sum'),\n",
    "    vol=('target', 'count'),\n",
    "    mean_prob=('probs_dev', 'mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_ae_dev is already defined and contains the necessary columns\n",
    "# Group by decile and calculate actual and expected bad rates\n",
    "act_exp = df_ae_dev.groupby('qtile').agg(\n",
    "    bads=('target', 'sum'),\n",
    "    vol=('target', 'count'),\n",
    "    mean_prob=('probs_dev', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate actual bad rate and expected bad rate\n",
    "act_exp['actual_bad_rate'] = act_exp['bads'] / act_exp['vol']\n",
    "act_exp['expected_bad_rate'] = act_exp['mean_prob']\n",
    "\n",
    "# Plot actual and expected bad rates by decile with expected bad rate on a secondary axis\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.plot(act_exp['qtile'], act_exp['actual_bad_rate'], marker='o', label='Actual Bad Rate', color='b')\n",
    "ax1.set_xlabel('Decile')\n",
    "ax1.set_ylabel('Actual Bad Rate', color='b')\n",
    "ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(act_exp['qtile'], act_exp['expected_bad_rate'], marker='x', label='Expected Bad Rate', color='r')\n",
    "ax2.set_ylabel('Expected Bad Rate', color='r')\n",
    "ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Actual vs Expected Bad Rate by Decile')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
